---
title: "Many-to-Many Multilingual Translation Model for Languages of Indonesia"
collection: publications
permalink: /publication/2023-08-25-indo-t5
excerpt: 'Indonesia is home to over 700 languages and most people speak their respective regional languages aside from the lingua franca. In this paper, we focus on the task of multilingual machine translation for 45 regional Indonesian languages and introduced Indo-T5 which leveraged the mT5 sequence-to-sequence language model as a baseline. Performances of bilingual and multilingual fine-tuning methods were also compared, in which we found that our models have outperformed current state-of-the-art translation models. We also investigate the use of religious texts from the Bible as an intermediate mid-resource translation domain for low-resource translation domain specialization. Our findings suggest that this two-step fine-tuning approach is highly effective in improving the quality of translations for low-resource text domains. Our results show an increase in SacreBLEU scores when evaluated on the low-resource NusaX dataset. We release our translation models for other researchers to leverage.'
date: 2023-08-25
venue: 'IEEE Access'
paperurl: 'https://ieeexplore.ieee.org/document/10230218'
citation: 'Wongso, W., Joyoadikusumo, A., Buana, B. S., & Suhartono, D. (2023). Many-to-Many Multilingual Translation Model for Languages of Indonesia. <i>IEEE Access</i>.'
---

## Abstract

Indonesia is home to over 700 languages and most people speak their respective regional languages aside from the lingua franca. In this paper, we focus on the task of multilingual machine translation for 45 regional Indonesian languages and introduced Indo-T5 which leveraged the mT5 sequence-to-sequence language model as a baseline. Performances of bilingual and multilingual fine-tuning methods were also compared, in which we found that our models have outperformed current state-of-the-art translation models. We also investigate the use of religious texts from the Bible as an intermediate mid-resource translation domain for low-resource translation domain specialization. Our findings suggest that this two-step fine-tuning approach is highly effective in improving the quality of translations for low-resource text domains. Our results show an increase in SacreBLEU scores when evaluated on the low-resource NusaX dataset. We release our translation models for other researchers to leverage.

## BibTeX Citation

```bibtex
@article{wongso2023many,
  title={Many-to-Many Multilingual Translation Model for Languages of Indonesia},
  author={Wongso, Wilson and Joyoadikusumo, Ananto and Buana, Brandon Scott and Suhartono, Derwin},
  journal={IEEE Access},
  year={2023},
  publisher={IEEE}
}
```